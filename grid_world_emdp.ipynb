{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use([\"science\", \"notebook\", \"grid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('./emdp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/swagatam/Desktop/misc/rl',\n",
       " '/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python38.zip',\n",
       " '/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8',\n",
       " '/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/lib-dynload',\n",
       " '',\n",
       " '/Users/swagatam/Library/Python/3.8/lib/python/site-packages',\n",
       " '/usr/local/lib/python3.8/site-packages',\n",
       " '/usr/local/lib/python3.8/site-packages/IPython/extensions',\n",
       " '/Users/swagatam/.ipython',\n",
       " './emdp']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring gridworld code from this repo: https://github.com/zafarali/emdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emdp.gridworld as gw\n",
    "from emdp.gridworld import build_simple_grid\n",
    "from emdp.gridworld.builder_tools import create_reward_matrix\n",
    "from emdp import actions\n",
    "from emdp.gridworld import GridWorldPlotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_SB_example41():\n",
    "    \n",
    "    \"\"\"\n",
    "    There are four actions possible in each state, A = {up, down, right, left}, which deterministically cause the\n",
    "    corresponding state transitions, except that actions that would take the agent off the grid in fact leave the\n",
    "    state unchanged.\n",
    "    This is an undiscounted, episodic task. \n",
    "    The reward is -1 on all transitions until the terminal state is reached.\n",
    "    The terminal state is shaded in the figure (although it is shown in two places, it is formally one state).\n",
    "    \"\"\"\n",
    "    size = 4\n",
    "    gamma = 1      # undiscounted episodic task\n",
    "    p_success = 1  # actions always successful\n",
    "    \n",
    "    \n",
    "    reward_spec = {(0, 0): 0, (size-1, size-1): 0}\n",
    "    \n",
    "    P = build_simple_grid(size=size, terminal_states=reward_spec.keys(), p_success=p_success)\n",
    "    R = create_reward_matrix(P.shape[0], size, reward_spec, action_space=4)\n",
    "    R += -1        # set all transitions to -1 as create_reward_matrix initializes to 0\n",
    "    R[0, :] = 0\n",
    "    R[15, :] = 0\n",
    "    R[16, :] = 0   # also set the created absorbing state's reward to 0\n",
    "    #print(R)\n",
    "    \n",
    "    # note: terminal/absorbing states can't be the starting state!\n",
    "    num_terminal_states = len(reward_spec.keys()) + 1  # add 1 for constructed absorbing state\n",
    "    p0 = np.ones(P.shape[0])\n",
    "    p0[0] = 0\n",
    "    p0[15] = 0\n",
    "    p0[16] = 0\n",
    "    p0 = p0/(P.shape[0]-num_terminal_states)  # uniform starting probability (assumed)\n",
    "    \n",
    "    return gw.GridWorldMDP(P, R, gamma, p0, terminal_states=reward_spec.keys(), size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdp = build_SB_example41()\n",
    "# state, reward, done, _ = mdp.step(actions.UP) # moves the agent up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 15],\n",
       " array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " (1, 1),\n",
       " 1,\n",
       " False,\n",
       " True)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdp.terminal_states, mdp.current_state, mdp.human_state, mdp.gamma, mdp.done, mdp.has_absorbing_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_state = one hot representation of state vector\n",
    "# human_state = (x, y) coordinate of current_state of the agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.07142857, 0.07142857, 0.07142857, 0.07142857,\n",
       "       0.07142857, 0.07142857, 0.07142857, 0.07142857, 0.07142857,\n",
       "       0.07142857, 0.07142857, 0.07142857, 0.07142857, 0.07142857,\n",
       "       0.        , 0.        ])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdp.p0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 4, 17)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdp.P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_SB_example35():\n",
    "#     \"\"\"\n",
    "#     Example 3.5 from (Sutton and Barto, 2018) pg 60 (March 2018 version).\n",
    "#     A rectangular Gridworld representation of size 5 x 5.\n",
    "\n",
    "#     Quotation from book:\n",
    "#     At each state, four actions are possible: north, south, east, and west, which deterministically\n",
    "#     cause the agent to move one cell in the respective direction on the grid. Actions that\n",
    "#     would take the agent off the grid leave its location unchanged, but also result in a reward\n",
    "#     of âˆ’1. Other actions result in a reward of 0, except those that move the agent out of the\n",
    "#     special states A and B. From state A, all four actions yield a reward of +10 and take the\n",
    "#     agent to A'. From state B, all actions yield a reward of +5 and take the agent to B'\n",
    "#     \"\"\"\n",
    "#     size = 5\n",
    "#     P = gw.build_simple_grid(size=size, p_success=1)\n",
    "#     # modify P to match dynamics from book.\n",
    "\n",
    "#     P[1, :, :] = 0 # first set the probability of all actions from state 1 to zero\n",
    "#     P[1, :, 21] = 1 # now set the probability of going from 1 to 21 with prob 1 for all actions\n",
    "\n",
    "#     P[3, :, :] = 0  # first set the probability of all actions from state 3 to zero\n",
    "#     P[3, :, 13] = 1  # now set the probability of going from 3 to 13 with prob 1 for all actions\n",
    "\n",
    "#     R = np.zeros((P.shape[0], P.shape[1])) # initialize a matrix of size |S|x|A|\n",
    "#     R[1, :] = +10\n",
    "#     R[3, :] = +1\n",
    "\n",
    "#     p0 = np.ones(P.shape[0])/P.shape[0] # uniform starting probability (assumed)\n",
    "#     gamma = 0.9\n",
    "\n",
    "#     terminal_states = []\n",
    "#     return gw.GridWorldMDP(P, R, gamma, p0, terminal_states, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mdp = build_SB_example35()\n",
    "# state, reward, done, _ = mdp.step(actions.UP) # moves the agent up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 15], 1, (1, 3), False, True)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdp = build_SB_example41()\n",
    "mdp.terminal_states, mdp.gamma, mdp.human_state, mdp.done, mdp.has_absorbing_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwp = GridWorldPlotter(mdp.size, mdp.has_absorbing_state) # alternatively you can use GridWorldPlotter.from_mdp(mdp)\n",
    "\n",
    "# collect/sample some trajectories from the GridWorldMDP object:\n",
    "\n",
    "trajectories = []\n",
    "for _ in range(1): # 3 trajectories\n",
    "#     trajectory = [mdp.reset()]\n",
    "    trajectory = [mdp.current_state]\n",
    "    for _ in range(100): # 10 steps maximum\n",
    "        state, reward, done, info = mdp.step(random.sample([actions.LEFT, actions.RIGHT, \n",
    "                                                        actions.UP, actions.DOWN], 1)[0])\n",
    "        trajectory.append(state)\n",
    "        if done:\n",
    "            trajectory= trajectory[:-1] # whichever terminal state it hits, it moves to (0, 0). so remove last\n",
    "            break\n",
    "    trajectories.append(trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectories[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='x', ylabel='y'>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10, 4))\n",
    "ax = fig.add_subplot(121)\n",
    "\n",
    "# trajectory\n",
    "gwp.plot_trajectories(ax, trajectories)\n",
    "gwp.plot_grid(ax)\n",
    "\n",
    "# heatmap\n",
    "ax = fig.add_subplot(122)\n",
    "gwp.plot_heatmap(ax, trajectories)\n",
    "gwp.plot_grid(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
